{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9527448b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7af113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import make_scorer\n",
    "from xgboost import XGBClassifier\n",
    "import featuretools as ft\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159c2989",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_org = pd.read_csv('train.csv', delimiter='|')\n",
    "\n",
    "# uncomment the following to exclude records w/ trustlevel >=3 (done by Haritha).\n",
    "# Jonas: I think this is not the right way to simply exlcude them. The right way would be to tell a model it should\n",
    "# always predict no fraud when trustLevel >= 3. But I actually have no idea how to do this.\n",
    "\n",
    "#dataframe_org.drop(dataframe_org.loc[dataframe_org['trustLevel']>=3].index, inplace=True)\n",
    "\n",
    "dataframe = dataframe_org.copy()\n",
    "\n",
    "\n",
    "########### manual feature generation ##########\n",
    "\n",
    "# totalScanned:\n",
    "dataframe['totalScanned'] = dataframe['scannedLineItemsPerSecond'] * dataframe['totalScanTimeInSeconds']\n",
    "# avgValuePerScan:\n",
    "dataframe['avgTimePerScan'] = 1/ dataframe['scannedLineItemsPerSecond']\n",
    "dataframe['avgValuePerScan'] = dataframe['avgTimePerScan'] * dataframe['valuePerSecond']\n",
    "# manual feature generation - \"totalScanned\" ratios\n",
    "# withoutRegisPerPosition\n",
    "dataframe['withoutRegisPerPosition'] = dataframe['scansWithoutRegistration'] / dataframe['totalScanned']\n",
    "# ratio of scansWithoutRegis in totalScan\n",
    "# equivalent to lineItemVoidsPerPosition\n",
    "# Might indicate how new or ambivalent a customer is. Expected to be higher for low \"trustLevel\"\n",
    "# quantiModPerPosition\n",
    "dataframe['quantiModPerPosition'] = dataframe['quantityModifications'] / dataframe['totalScanned']\n",
    "# ratio of quanityMods in totalScan\n",
    "# manual feature generation - \"grandTotal\" ratios\n",
    "# lineItemVoidsPerTotal\n",
    "dataframe['lineItemVoidsPerTotal'] = dataframe['lineItemVoids'] / dataframe['grandTotal']\n",
    "# withoutRegisPerTotal\n",
    "dataframe['withoutRegisPerTotal'] = dataframe['scansWithoutRegistration'] / dataframe['grandTotal']\n",
    "# quantiModPerTotal\n",
    "dataframe['quantiModPerTotal'] = dataframe['quantityModifications'] / dataframe['grandTotal']\n",
    "# manual feature generation - \"totalScanTimeInSeconds\" ratios\n",
    "# lineItemVoidsPerTime\n",
    "dataframe['lineItemVoidsPerTime'] = dataframe['lineItemVoids'] / dataframe['totalScanTimeInSeconds']\n",
    "# withoutRegisPerTime\n",
    "dataframe['withoutRegisPerTime'] = dataframe['scansWithoutRegistration'] / dataframe['totalScanTimeInSeconds']\n",
    "# quantiModPerTime\n",
    "dataframe['quantiModPerTime'] = dataframe['quantityModifications'] / dataframe['totalScanTimeInSeconds']\n",
    "\n",
    "########### end manual feature generation ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2a28ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_base=dataframe.drop('fraud',axis=1)\n",
    "y_base=dataframe['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea8209a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523b4a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# sc=StandardScaler()\n",
    "# X_base=sc.fit_transform(X_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42378a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trustLevel</th>\n",
       "      <th>totalScanTimeInSeconds</th>\n",
       "      <th>grandTotal</th>\n",
       "      <th>lineItemVoids</th>\n",
       "      <th>scansWithoutRegistration</th>\n",
       "      <th>quantityModifications</th>\n",
       "      <th>scannedLineItemsPerSecond</th>\n",
       "      <th>valuePerSecond</th>\n",
       "      <th>lineItemVoidsPerPosition</th>\n",
       "      <th>fraud</th>\n",
       "      <th>...</th>\n",
       "      <th>avgTimePerScan</th>\n",
       "      <th>avgValuePerScan</th>\n",
       "      <th>withoutRegisPerPosition</th>\n",
       "      <th>quantiModPerPosition</th>\n",
       "      <th>lineItemVoidsPerTotal</th>\n",
       "      <th>withoutRegisPerTotal</th>\n",
       "      <th>quantiModPerTotal</th>\n",
       "      <th>lineItemVoidsPerTime</th>\n",
       "      <th>withoutRegisPerTime</th>\n",
       "      <th>quantiModPerTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1054</td>\n",
       "      <td>54.70</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.027514</td>\n",
       "      <td>0.051898</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.344828</td>\n",
       "      <td>1.886207</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.127971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054845</td>\n",
       "      <td>0.006641</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>108</td>\n",
       "      <td>27.36</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.129630</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.714286</td>\n",
       "      <td>1.954286</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.182749</td>\n",
       "      <td>0.073099</td>\n",
       "      <td>0.146199</td>\n",
       "      <td>0.046296</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1516</td>\n",
       "      <td>62.16</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>0.041003</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>116.615385</td>\n",
       "      <td>4.781538</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.048263</td>\n",
       "      <td>0.160875</td>\n",
       "      <td>0.080438</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.006596</td>\n",
       "      <td>0.003298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1791</td>\n",
       "      <td>92.31</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.051541</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>61.758621</td>\n",
       "      <td>3.183103</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.086665</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.002233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>430</td>\n",
       "      <td>81.53</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062791</td>\n",
       "      <td>0.189605</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.925926</td>\n",
       "      <td>3.019630</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.036796</td>\n",
       "      <td>0.085858</td>\n",
       "      <td>0.024531</td>\n",
       "      <td>0.006977</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.004651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874</th>\n",
       "      <td>1</td>\n",
       "      <td>321</td>\n",
       "      <td>76.03</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.071651</td>\n",
       "      <td>0.236854</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.956522</td>\n",
       "      <td>3.305652</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.105222</td>\n",
       "      <td>0.092069</td>\n",
       "      <td>0.026305</td>\n",
       "      <td>0.024922</td>\n",
       "      <td>0.021807</td>\n",
       "      <td>0.006231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>1</td>\n",
       "      <td>397</td>\n",
       "      <td>41.89</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.065491</td>\n",
       "      <td>0.105516</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15.269231</td>\n",
       "      <td>1.611154</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.119360</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.012594</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1876</th>\n",
       "      <td>4</td>\n",
       "      <td>316</td>\n",
       "      <td>41.83</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.094937</td>\n",
       "      <td>0.132373</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.533333</td>\n",
       "      <td>1.394333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.119531</td>\n",
       "      <td>0.191250</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>0.003165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>2</td>\n",
       "      <td>685</td>\n",
       "      <td>62.68</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.035036</td>\n",
       "      <td>0.091504</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.541667</td>\n",
       "      <td>2.611667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.015954</td>\n",
       "      <td>0.095724</td>\n",
       "      <td>0.031908</td>\n",
       "      <td>0.001460</td>\n",
       "      <td>0.008759</td>\n",
       "      <td>0.002920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>4</td>\n",
       "      <td>1140</td>\n",
       "      <td>38.03</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.033360</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.001579</td>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.052590</td>\n",
       "      <td>0.078885</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.002632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1879 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       "0              5                    1054       54.70              7   \n",
       "1              3                     108       27.36              5   \n",
       "2              3                    1516       62.16              3   \n",
       "3              6                    1791       92.31              8   \n",
       "4              5                     430       81.53              3   \n",
       "...          ...                     ...         ...            ...   \n",
       "1874           1                     321       76.03              8   \n",
       "1875           1                     397       41.89              5   \n",
       "1876           4                     316       41.83              5   \n",
       "1877           2                     685       62.68              1   \n",
       "1878           4                    1140       38.03              2   \n",
       "\n",
       "      scansWithoutRegistration  quantityModifications  \\\n",
       "0                            0                      3   \n",
       "1                            2                      4   \n",
       "2                           10                      5   \n",
       "3                            4                      4   \n",
       "4                            7                      2   \n",
       "...                        ...                    ...   \n",
       "1874                         7                      2   \n",
       "1875                         5                      0   \n",
       "1876                         8                      1   \n",
       "1877                         6                      2   \n",
       "1878                         2                      3   \n",
       "\n",
       "      scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \\\n",
       "0                      0.027514        0.051898                  0.241379   \n",
       "1                      0.129630        0.253333                  0.357143   \n",
       "2                      0.008575        0.041003                  0.230769   \n",
       "3                      0.016192        0.051541                  0.275862   \n",
       "4                      0.062791        0.189605                  0.111111   \n",
       "...                         ...             ...                       ...   \n",
       "1874                   0.071651        0.236854                  0.347826   \n",
       "1875                   0.065491        0.105516                  0.192308   \n",
       "1876                   0.094937        0.132373                  0.166667   \n",
       "1877                   0.035036        0.091504                  0.041667   \n",
       "1878                   0.016667        0.033360                  0.105263   \n",
       "\n",
       "      fraud  ...  avgTimePerScan  avgValuePerScan  withoutRegisPerPosition  \\\n",
       "0         0  ...       36.344828         1.886207                 0.000000   \n",
       "1         0  ...        7.714286         1.954286                 0.142857   \n",
       "2         0  ...      116.615385         4.781538                 0.769231   \n",
       "3         0  ...       61.758621         3.183103                 0.137931   \n",
       "4         0  ...       15.925926         3.019630                 0.259259   \n",
       "...     ...  ...             ...              ...                      ...   \n",
       "1874      0  ...       13.956522         3.305652                 0.304348   \n",
       "1875      1  ...       15.269231         1.611154                 0.192308   \n",
       "1876      0  ...       10.533333         1.394333                 0.266667   \n",
       "1877      0  ...       28.541667         2.611667                 0.250000   \n",
       "1878      0  ...       60.000000         2.001579                 0.105263   \n",
       "\n",
       "      quantiModPerPosition  lineItemVoidsPerTotal  withoutRegisPerTotal  \\\n",
       "0                 0.103448               0.127971              0.000000   \n",
       "1                 0.285714               0.182749              0.073099   \n",
       "2                 0.384615               0.048263              0.160875   \n",
       "3                 0.137931               0.086665              0.043332   \n",
       "4                 0.074074               0.036796              0.085858   \n",
       "...                    ...                    ...                   ...   \n",
       "1874              0.086957               0.105222              0.092069   \n",
       "1875              0.000000               0.119360              0.119360   \n",
       "1876              0.033333               0.119531              0.191250   \n",
       "1877              0.083333               0.015954              0.095724   \n",
       "1878              0.157895               0.052590              0.052590   \n",
       "\n",
       "      quantiModPerTotal  lineItemVoidsPerTime  withoutRegisPerTime  \\\n",
       "0              0.054845              0.006641             0.000000   \n",
       "1              0.146199              0.046296             0.018519   \n",
       "2              0.080438              0.001979             0.006596   \n",
       "3              0.043332              0.004467             0.002233   \n",
       "4              0.024531              0.006977             0.016279   \n",
       "...                 ...                   ...                  ...   \n",
       "1874           0.026305              0.024922             0.021807   \n",
       "1875           0.000000              0.012594             0.012594   \n",
       "1876           0.023906              0.015823             0.025316   \n",
       "1877           0.031908              0.001460             0.008759   \n",
       "1878           0.078885              0.001754             0.001754   \n",
       "\n",
       "      quantiModPerTime  \n",
       "0             0.002846  \n",
       "1             0.037037  \n",
       "2             0.003298  \n",
       "3             0.002233  \n",
       "4             0.004651  \n",
       "...                ...  \n",
       "1874          0.006231  \n",
       "1875          0.000000  \n",
       "1876          0.003165  \n",
       "1877          0.002920  \n",
       "1878          0.002632  \n",
       "\n",
       "[1879 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a156079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test = pd.read_csv('test.csv', delimiter='|')\n",
    "dataframe_test['totalScanned'] = dataframe_test['scannedLineItemsPerSecond'] * dataframe_test['totalScanTimeInSeconds']\n",
    "# avgValuePerScan:\n",
    "dataframe_test['avgTimePerScan'] = 1/ dataframe_test['scannedLineItemsPerSecond']\n",
    "dataframe_test['avgValuePerScan'] = dataframe_test['avgTimePerScan'] * dataframe_test['valuePerSecond']\n",
    "# manual feature generation - \"totalScanned\" ratios\n",
    "# withoutRegisPerPosition\n",
    "dataframe_test['withoutRegisPerPosition'] = dataframe_test['scansWithoutRegistration'] / dataframe_test['totalScanned']\n",
    "# ratio of scansWithoutRegis in totalScan\n",
    "# equivalent to lineItemVoidsPerPosition\n",
    "# Might indicate how new or ambivalent a customer is. Expected to be higher for low \"trustLevel\"\n",
    "# quantiModPerPosition\n",
    "dataframe_test['quantiModPerPosition'] = dataframe_test['quantityModifications'] / dataframe_test['totalScanned']\n",
    "# ratio of quanityMods in totalScan\n",
    "# manual feature generation - \"grandTotal\" ratios\n",
    "# lineItemVoidsPerTotal\n",
    "dataframe_test['lineItemVoidsPerTotal'] = dataframe_test['lineItemVoids'] / dataframe_test['grandTotal']\n",
    "# withoutRegisPerTotal\n",
    "dataframe_test['withoutRegisPerTotal'] = dataframe_test['scansWithoutRegistration'] / dataframe_test['grandTotal']\n",
    "# quantiModPerTotal\n",
    "dataframe_test['quantiModPerTotal'] = dataframe_test['quantityModifications'] / dataframe_test['grandTotal']\n",
    "# manual feature generation - \"totalScanTimeInSeconds\" ratios\n",
    "# lineItemVoidsPerTime\n",
    "dataframe_test['lineItemVoidsPerTime'] = dataframe_test['lineItemVoids'] / dataframe_test['totalScanTimeInSeconds']\n",
    "# withoutRegisPerTime\n",
    "dataframe_test['withoutRegisPerTime'] = dataframe_test['scansWithoutRegistration'] / dataframe_test['totalScanTimeInSeconds']\n",
    "# quantiModPerTime\n",
    "dataframe_test['quantiModPerTime'] = dataframe_test['quantityModifications'] / dataframe_test['totalScanTimeInSeconds']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d530e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f38a4d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b676f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sol=pd.read_csv('sol_dmc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4bedc062",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78156b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76e7c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_test=dataframe_test.replace([np.nan,np.inf,-np.inf],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f552ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[470630,   3764],\n",
       "       [  3657,  20070]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic=LogisticRegression(penalty='none',max_iter=175)\n",
    "modelm=logistic.fit(X=X_base,y=y_base)\n",
    "predictions1=modelm.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predictions1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9f312a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:46:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[471600,   2794],\n",
       "       [  4640,  19087]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb=XGBClassifier()\n",
    "model=xgb.fit(X=X_base,y=y_base)\n",
    "predictions=model.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f191c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[471734,   2660],\n",
       "       [  2684,  21043]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada=AdaBoostClassifier(learning_rate=0.95,n_estimators=100)\n",
    "model18=ada.fit(X=X_base,y=y_base)\n",
    "predictions18=model18.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predictions18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "849b15a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trustLevel                   0\n",
       "totalScanTimeInSeconds       0\n",
       "grandTotal                   0\n",
       "lineItemVoids                0\n",
       "scansWithoutRegistration     0\n",
       "quantityModifications        0\n",
       "scannedLineItemsPerSecond    0\n",
       "valuePerSecond               0\n",
       "lineItemVoidsPerPosition     0\n",
       "totalScanned                 0\n",
       "avgTimePerScan               0\n",
       "avgValuePerScan              0\n",
       "withoutRegisPerPosition      0\n",
       "quantiModPerPosition         0\n",
       "lineItemVoidsPerTotal        0\n",
       "withoutRegisPerTotal         0\n",
       "quantiModPerTotal            0\n",
       "lineItemVoidsPerTime         0\n",
       "withoutRegisPerTime          0\n",
       "quantiModPerTime             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f6a8f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['trustLevel', 'totalScanTimeInSeconds', 'grandTotal', 'lineItemVoids',\n",
       "       'scansWithoutRegistration', 'quantityModifications',\n",
       "       'scannedLineItemsPerSecond', 'valuePerSecond',\n",
       "       'lineItemVoidsPerPosition', 'totalScanned', 'avgTimePerScan',\n",
       "       'avgValuePerScan', 'withoutRegisPerPosition', 'quantiModPerPosition',\n",
       "       'lineItemVoidsPerTotal', 'withoutRegisPerTotal', 'quantiModPerTotal',\n",
       "       'lineItemVoidsPerTime', 'withoutRegisPerTime', 'quantiModPerTime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "491d4db5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "trustLevel                   498121\n",
       "totalScanTimeInSeconds       498121\n",
       "grandTotal                   498121\n",
       "lineItemVoids                498121\n",
       "scansWithoutRegistration     498121\n",
       "quantityModifications        498121\n",
       "scannedLineItemsPerSecond    498121\n",
       "valuePerSecond               498121\n",
       "lineItemVoidsPerPosition     498121\n",
       "totalScanned                 498121\n",
       "avgTimePerScan               498121\n",
       "avgValuePerScan              498121\n",
       "withoutRegisPerPosition      498121\n",
       "quantiModPerPosition         498121\n",
       "lineItemVoidsPerTotal        498121\n",
       "withoutRegisPerTotal         498121\n",
       "quantiModPerTotal            498121\n",
       "lineItemVoidsPerTime         498121\n",
       "withoutRegisPerTime          498121\n",
       "quantiModPerTime             498121\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isfinite(dataframe_test).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0f277",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea0d8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36e15367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[472255,   2139],\n",
       "       [  9162,  14565]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random=RandomForestClassifier(n_estimators= 75,\n",
    " min_samples_split= 2,\n",
    " min_samples_leaf= 1,\n",
    " max_features= 'auto')\n",
    "clf=random.fit(X_base,y_base)\n",
    "predict=clf.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c324441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_base1=sc.fit_transform(X_base)\n",
    "dataframe_test1=sc.fit_transform(dataframe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "727698a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[471312,   3082],\n",
       "       [  2116,  21611]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv=SVC(C=100, gamma=0.001, kernel='rbf')\n",
    "svc=sv.fit(X_base1,y_base)\n",
    "pred=svc.predict(dataframe_test1)\n",
    "confusion_matrix(df_sol['fraud'],pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22040178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[470649,   3745],\n",
       "       [  1406,  22321]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sv1=SVC(C=800, gamma=0.0009, kernel='rbf')\n",
    "svc1=sv1.fit(X_base1,y_base)\n",
    "pred11=svc1.predict(dataframe_test1)\n",
    "confusion_matrix(df_sol['fraud'],pred11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45ea1268",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voter=pd.DataFrame()\n",
    "df_voter['svc']=pred11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ede8321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d666ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.947 total time=   0.2s\n",
      "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.947 total time=   0.2s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.947 total time=   0.2s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.947 total time=   0.3s\n",
      "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.947 total time=   0.2s\n",
      "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.947 total time=   0.2s\n",
      "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.941 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.941 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.944 total time=   0.1s\n",
      "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.947 total time=   0.3s\n",
      "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.947 total time=   0.3s\n",
      "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.941 total time=   0.2s\n",
      "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.920 total time=   0.0s\n",
      "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.912 total time=   0.0s\n",
      "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.931 total time=   0.0s\n",
      "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.912 total time=   0.0s\n",
      "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.931 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.941 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.944 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.947 total time=   0.0s\n",
      "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.947 total time=   0.3s\n",
      "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.947 total time=   0.3s\n",
      "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.939 total time=   0.3s\n",
      "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.941 total time=   0.2s\n",
      "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.915 total time=   0.0s\n",
      "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.907 total time=   0.0s\n",
      "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.928 total time=   0.0s\n",
      "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.910 total time=   0.0s\n",
      "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.939 total time=   0.0s\n",
      "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.949 total time=   0.0s\n",
      "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.936 total time=   0.0s\n",
      "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.939 total time=   0.0s\n",
      "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.941 total time=   0.0s\n",
      "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.944 total time=   0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.947 total time=   0.2s\n",
      "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.944 total time=   0.3s\n",
      "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.947 total time=   0.3s\n",
      "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.941 total time=   0.2s\n",
      "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.939 total time=   0.2s\n",
      "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.939 total time=   0.3s\n",
      "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.944 total time=   0.2s\n",
      "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.915 total time=   0.0s\n",
      "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.907 total time=   0.0s\n",
      "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.928 total time=   0.0s\n",
      "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.910 total time=   0.0s\n",
      "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.925 total time=   0.0s\n",
      "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.957 total time=   0.0s\n",
      "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.957 total time=   0.0s\n",
      "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.934 total time=   0.0s\n",
      "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.939 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['rbf']}\n",
    " \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    " \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_base, y_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30391e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "378a10dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': 5, 'min_child_weight': 3}, 0.9985352112676056)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,10,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n",
    "gsearch1.fit(X_base,y_base)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de7962f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'learning_rate': 0.16}, 0.9986934942991281)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'learning_rate':[i/100.0 for i in range(1,100)]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n",
    "gsearch1.fit(X_base,y_base)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb56d29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 250}, 0.9987256874580819)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'n_estimators':[i for i in range(100,500,50)]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.16, n_estimators=250, max_depth=5,reg_alpha=1e-05,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n",
    "gsearch1.fit(X_base,y_base)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9b985ee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'scale_pos_weight': 1}, 0.9987256874580819)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'scale_pos_weight':[i for i in range(1,25)]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.16, n_estimators=250, max_depth=5,reg_alpha=1e-05,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n",
    "gsearch1.fit(X_base,y_base)\n",
    "gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e22422f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:50:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[469575,   4819],\n",
       "       [  2561,  21166]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#trying XGB after hyper-parameter tuning\n",
    "xgbnew=XGBClassifier(learning_rate =0.16, n_estimators=250, max_depth=5,reg_alpha=1e-05,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=5, scale_pos_weight=20, seed=27)\n",
    "modelnew=xgbnew.fit(X=X_base,y=y_base)\n",
    "predictionsnew=modelnew.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predictionsnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4294f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voter['logistic']=predictions1\n",
    "df_voter['ada']=predictions18\n",
    "df_voter['xgb']=predictionsnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be5e5a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498121, 4)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_voter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "048d8c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498121"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataframe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b75e1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=[]\n",
    "naya_list=[]\n",
    "imp_list=[]\n",
    "for row in range(len(dataframe_test)):\n",
    "    for column in range(4):\n",
    "        arr.append(df_voter.loc[row][column])\n",
    "    imp_list.append(1.2*arr[0]+arr[1]+1.1*arr[2]+1.1*arr[3])    \n",
    "    if imp_list[0]>2.4:\n",
    "        naya_list.append(1)\n",
    "    else:\n",
    "        naya_list.append(0)\n",
    "    imp_list=[]\n",
    "    arr=[]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f77f03ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  ...],\n",
       "         trustLevel  totalScanTimeInSeconds  grandTotal  lineItemVoids  \\\n",
       " 0                4                     467       88.48              4   \n",
       " 1                3                    1004       58.99              7   \n",
       " 2                1                     162       14.00              4   \n",
       " 3                5                     532       84.79              9   \n",
       " 4                5                     890       42.16              4   \n",
       " ...            ...                     ...         ...            ...   \n",
       " 498116           4                     783       59.10              2   \n",
       " 498117           1                     278       98.90              9   \n",
       " 498118           3                     300        5.41              6   \n",
       " 498119           2                    1524       33.97              2   \n",
       " 498120           3                    1456       56.97             11   \n",
       " \n",
       "         scansWithoutRegistration  quantityModifications  \\\n",
       " 0                              8                      4   \n",
       " 1                              6                      1   \n",
       " 2                              5                      4   \n",
       " 3                              3                      4   \n",
       " 4                              0                      0   \n",
       " ...                          ...                    ...   \n",
       " 498116                         2                      0   \n",
       " 498117                         5                      4   \n",
       " 498118                         6                      4   \n",
       " 498119                         5                      3   \n",
       " 498120                         7                      2   \n",
       " \n",
       "         scannedLineItemsPerSecond  valuePerSecond  lineItemVoidsPerPosition  \\\n",
       " 0                        0.014989        0.189465                  0.571429   \n",
       " 1                        0.026892        0.058755                  0.259259   \n",
       " 2                        0.006173        0.086420                  4.000000   \n",
       " 3                        0.026316        0.159380                  0.642857   \n",
       " 4                        0.021348        0.047371                  0.210526   \n",
       " ...                           ...             ...                       ...   \n",
       " 498116                   0.012771        0.075479                  0.200000   \n",
       " 498117                   0.050360        0.355755                  0.642857   \n",
       " 498118                   0.030000        0.018033                  0.666667   \n",
       " 498119                   0.005906        0.022290                  0.222222   \n",
       " 498120                   0.019231        0.039128                  0.392857   \n",
       " \n",
       "         totalScanned  avgTimePerScan  avgValuePerScan  \\\n",
       " 0                7.0       66.714286        12.640000   \n",
       " 1               27.0       37.185185         2.184815   \n",
       " 2                1.0      162.000000        14.000000   \n",
       " 3               14.0       38.000000         6.056429   \n",
       " 4               19.0       46.842105         2.218947   \n",
       " ...              ...             ...              ...   \n",
       " 498116          10.0       78.300000         5.910000   \n",
       " 498117          14.0       19.857143         7.064286   \n",
       " 498118           9.0       33.333333         0.601111   \n",
       " 498119           9.0      169.333333         3.774444   \n",
       " 498120          28.0       52.000000         2.034643   \n",
       " \n",
       "         withoutRegisPerPosition  quantiModPerPosition  lineItemVoidsPerTotal  \\\n",
       " 0                      1.142857              0.571429               0.045208   \n",
       " 1                      0.222222              0.037037               0.118664   \n",
       " 2                      5.000000              4.000000               0.285714   \n",
       " 3                      0.214286              0.285714               0.106145   \n",
       " 4                      0.000000              0.000000               0.094877   \n",
       " ...                         ...                   ...                    ...   \n",
       " 498116                 0.200000              0.000000               0.033841   \n",
       " 498117                 0.357143              0.285714               0.091001   \n",
       " 498118                 0.666667              0.444444               1.109057   \n",
       " 498119                 0.555556              0.333333               0.058875   \n",
       " 498120                 0.250000              0.071429               0.193084   \n",
       " \n",
       "         withoutRegisPerTotal  quantiModPerTotal  lineItemVoidsPerTime  \\\n",
       " 0                   0.090416           0.045208              0.008565   \n",
       " 1                   0.101712           0.016952              0.006972   \n",
       " 2                   0.357143           0.285714              0.024691   \n",
       " 3                   0.035382           0.047175              0.016917   \n",
       " 4                   0.000000           0.000000              0.004494   \n",
       " ...                      ...                ...                   ...   \n",
       " 498116              0.033841           0.000000              0.002554   \n",
       " 498117              0.050556           0.040445              0.032374   \n",
       " 498118              1.109057           0.739372              0.020000   \n",
       " 498119              0.147189           0.088313              0.001312   \n",
       " 498120              0.122872           0.035106              0.007555   \n",
       " \n",
       "         withoutRegisPerTime  quantiModPerTime  \n",
       " 0                  0.017131          0.008565  \n",
       " 1                  0.005976          0.000996  \n",
       " 2                  0.030864          0.024691  \n",
       " 3                  0.005639          0.007519  \n",
       " 4                  0.000000          0.000000  \n",
       " ...                     ...               ...  \n",
       " 498116             0.002554          0.000000  \n",
       " 498117             0.017986          0.014388  \n",
       " 498118             0.020000          0.013333  \n",
       " 498119             0.003281          0.001969  \n",
       " 498120             0.004808          0.001374  \n",
       " \n",
       " [498121 rows x 20 columns])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naya_list,dataframe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a2535f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[471853,   2541],\n",
       "       [  2851,  20876]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_sol['fraud'],pd.Series(naya_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f70be72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "982812b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    474394\n",
      "           1       0.81      0.89      0.85     23727\n",
      "\n",
      "    accuracy                           0.99    498121\n",
      "   macro avg       0.90      0.94      0.92    498121\n",
      "weighted avg       0.99      0.99      0.99    498121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df_sol['fraud'],predictionsnew))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b9a40fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[23:52:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGB w/ PCA & featuretools & SelectKBest on data w/ additional manual features generated: 0.9920212765957446\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=10)\n",
    "\n",
    "features = []\n",
    "features.append(('pca', PCA(n_components=8)))\n",
    "features.append(('select_best', SelectKBest(k=4)))\n",
    "feature_union = FeatureUnion(features)\n",
    "# create pipeline\n",
    "estimators = []\n",
    "estimators.append(('feature_union', feature_union))\n",
    "estimators.append(('xgb', XGBClassifier(learning_rate =0.16, n_estimators=250, max_depth=5,reg_alpha=1e-05,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=5, scale_pos_weight=20, seed=27)))\n",
    "\n",
    "xgb_af = Pipeline(estimators)\n",
    "\n",
    "print('XGB w/ PCA & featuretools & SelectKBest on data w/ additional manual features generated: {}'.format(np.mean(cross_validate(xgb_af, X_base, y=y_base, cv=cv)['test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1435413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:53:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "xgc_af=xgb_af.fit(X_base,y_base)\n",
    "pf=xgc_af.predict(dataframe_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6523e1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(498121, 20)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "baec186d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[469610,   4784],\n",
       "       [  2666,  21061]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df_sol['fraud'],pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b85bca41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "def upsample_SMOTE(X, y, ratio=0.08):\n",
    "    sm = SMOTE(random_state=23, sampling_strategy=ratio)\n",
    "    X_train_sm, y_train_sm = sm.fit_resample(X, y)\n",
    "    print(len(X_train_sm), len(y_train_sm))\n",
    "    return X_train_sm, y_train_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1e11aa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2218 2218\n"
     ]
    }
   ],
   "source": [
    "X_train_sm,y_train_sm=upsample_SMOTE(X_base, y_base, ratio=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ace95c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sm=pd.DataFrame(X_train_sm)\n",
    "y_train_sm=pd.DataFrame(y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ccf3f3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=X_train_sm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f3804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af109001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pca in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (1.6.2)\n",
      "Requirement already satisfied: wget in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from pca) (3.2)\n",
      "Requirement already satisfied: sklearn in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from pca) (0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from pca) (1.21.2)\n",
      "Requirement already satisfied: colourmap in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from pca) (0.1.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from pca) (1.7.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from pca) (3.4.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from pca) (1.3.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from pca) (4.62.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from matplotlib->pca) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from matplotlib->pca) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from matplotlib->pca) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from matplotlib->pca) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from matplotlib->pca) (1.3.1)\n",
      "Requirement already satisfied: six in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->pca) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from pandas->pca) (2021.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from sklearn->pca) (1.0.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->pca) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn->pca) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vedant kathe\\anaconda3\\lib\\site-packages (from tqdm->pca) (0.4.4)\n",
      "[pca] >Processing dataframe..\n",
      "[pca] >The PCA reduction is performed on the [20] columns of the input dataframe.\n",
      "[pca] >Fitting using PCA..\n",
      "[pca] >Computing loadings and PCs..\n",
      "[pca] >Computing explained variance..\n",
      "[pca] >Outlier detection using Hotelling T2 test with alpha=[0.05] and n_components=[15]\n",
      "[pca] >Outlier detection using SPE/DmodX with n_std=[2]\n"
     ]
    }
   ],
   "source": [
    "!pip install pca\n",
    "from pca import pca\n",
    "model = pca(n_components=15)\n",
    "# Fit transform\n",
    "out = model.fit_transform(X_train_sm)\n",
    "\n",
    "# Print the top features. The results show that f1 is best, followed by f2 etc\n",
    "feture=list(out['topfeat']['feature'][:15])\n",
    "feture=list(set(feture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7477c38e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\VEDANT~1\\AppData\\Local\\Temp/ipykernel_19732/3355619456.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'my_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(my_model.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d8d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=X_train_sm[feture]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b47b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89456b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=dataframe_test[feture]\n",
    "xgbnew1=XGBClassifier(learning_rate =0.16, n_estimators=250, max_depth=5,reg_alpha=1e-05,\n",
    " min_child_weight=3, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=5, scale_pos_weight=20, seed=27)\n",
    "modelnew1=xgbnew1.fit(X=X_train_sm,y=y_train_sm)\n",
    "predictionsnew1=modelnew1.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],predictionsnew1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d030d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf8 = MLPClassifier(random_state=1, max_iter=100,hidden_layer_sizes=(90,), activation='relu',solver='adam').fit(X_base, y_base)\n",
    "cf=clf8.predict(dataframe_test)\n",
    "confusion_matrix(df_sol['fraud'],cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ce94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_voter.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e9f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finally lets see the best model\n",
    "print(confusion_matrix(df_sol['fraud'],df_voter['svc']))\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print(confusion_matrix(df_sol['fraud'],df_voter['logistic']))\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print(confusion_matrix(df_sol['fraud'],df_voter['ada']))\n",
    "print('-----------------------------------------------------------------------------------------------------')\n",
    "print(confusion_matrix(df_sol['fraud'],df_voter['xgb']))\n",
    "print('-----------------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270e7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model_pkl', 'wb') as files:\n",
    "    pickle.dump(svc1, files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9911ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
